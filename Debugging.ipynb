{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import loader\n",
    "import model\n",
    "from general import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eloader = loader.Data('evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, masks, depths, annos = eloader.load_batch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crop and resize test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgs, masks, depths, annos = eloader.load_batch(8)\n",
    "for idx in range(2):\n",
    "\n",
    "    plt.imshow(imgs[idx])\n",
    "    plt.show()\n",
    "\n",
    "    hands = (np.ones(masks.shape) < masks).astype(int)\n",
    "    plt.imshow(hands[idx,:,:,0], 'gray')\n",
    "    plt.show()\n",
    "    \n",
    "    bb_list, crsize_list, offset_list = crop_and_resize(imgs, binary_mask)\n",
    "\n",
    "    oh = tf.cast(tf.stack(offset_list)[:,0], tf.int32)\n",
    "    ow = tf.cast(tf.stack(offset_list)[:,1], tf.int32)\n",
    "\n",
    "    th = tf.cast(tf.stack(crsize_list)[:,0], tf.int32)\n",
    "    tw = tf.cast(tf.stack(crsize_list)[:,1], tf.int32)\n",
    "    \n",
    "    cr_imgs = sess.run(tf.image.crop_to_bounding_box(imgs[idx],\n",
    "                                                 oh[idx],\n",
    "                                                 ow[idx],\n",
    "                                                 th[idx],\n",
    "                                                 tw[idx]))\n",
    "    plt.imshow(cr_imgs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mask = hands[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bb_list, crsize_list, offset_list = crop_and_resize(imgs, binary_mask)\n",
    "\n",
    "oh = tf.cast(tf.stack(offset_list)[:,0], tf.int32)\n",
    "ow = tf.cast(tf.stack(offset_list)[:,1], tf.int32)\n",
    "\n",
    "th = tf.cast(tf.stack(crsize_list)[:,0], tf.int32)\n",
    "tw = tf.cast(tf.stack(crsize_list)[:,1], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_imgs = sess.run(tf.image.crop_to_bounding_box(imgs[idx],\n",
    "                                                 oh[idx],\n",
    "                                                 ow[idx],\n",
    "                                                 th[idx],\n",
    "                                                 tw[idx]))\n",
    "plt.imshow(cr_imgs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_resize(imgs, binary_mask):\n",
    "    # implement\n",
    "    imgs_cr = imgs\n",
    "    crop_offset = tf.ones([8, 2])\n",
    "    crop_scale = tf.ones([8, 1])\n",
    "\n",
    "    binary_mask = tf.cast(binary_mask, tf.int32)\n",
    "    binary_mask = tf.equal(binary_mask, 1)\n",
    "    s = binary_mask.get_shape().as_list()\n",
    "\n",
    "    x_range = tf.expand_dims(tf.range(s[1]), 1)\n",
    "    y_range = tf.expand_dims(tf.range(s[2]), 0)\n",
    "    X = tf.tile(x_range, [1, s[2]])\n",
    "    Y = tf.tile(y_range, [s[1], 1])\n",
    "\n",
    "    # bounding box\n",
    "    bb_list = []\n",
    "    crop_size_list = []\n",
    "    offset_list = []\n",
    "\n",
    "    for i in range(s[0]):\n",
    "        X_masked = tf.cast(tf.boolean_mask(X, binary_mask[i, :, :]), tf.float32)\n",
    "        Y_masked = tf.cast(tf.boolean_mask(Y, binary_mask[i, :, :]), tf.float32)\n",
    "\n",
    "        x_min = tf.reduce_min(X_masked)\n",
    "        x_max = tf.reduce_max(X_masked)\n",
    "        y_min = tf.reduce_min(Y_masked)\n",
    "        y_max = tf.reduce_max(Y_masked)\n",
    "\n",
    "        start = tf.stack([x_min, y_min])\n",
    "        end = tf.stack([x_max, y_max])\n",
    "        bb = tf.stack([start, end], 1)\n",
    "        # bb = [x_min, y_min, x_max, y_max]\n",
    "        \n",
    "        offset_list.append([x_min, y_min])\n",
    "        bb_list.append(bb)\n",
    "\n",
    "        crop_size_x = x_max - x_min\n",
    "        crop_size_y = y_max - y_min\n",
    "\n",
    "        crop_size_list.append([crop_size_x, crop_size_y])\n",
    "        \n",
    "    return bb_list, crop_size_list, offset_list\n",
    "    # return imgs_cr, crop_offset, crop_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_test = {\n",
    "    'ID' : 'test_model',\n",
    "    'n_iter' : 20000,\n",
    "    'n_prt' : 100,\n",
    "    'input_h' : 320,\n",
    "    'input_w' : 320,\n",
    "    'input_ch' : 3,\n",
    "    'n_output' : 10,\n",
    "    'n_batch' : 8,\n",
    "    'n_save' : 1000,\n",
    "    'n_history' : 50,\n",
    "    'LR' : 1e-5,\n",
    "    'random_crop' : False,\n",
    "    'training' : False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in annos.items():\n",
    "    print(key, val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.range(320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = tf.expand_dims(tf.range(320), 1)\n",
    "x_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.tile(x_range, [1, 320])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.stack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,2,3],[4,5,6]]\n",
    "tf.stack(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.ones([8,320,320,1])[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.tile?ㅁ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annos['uv'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annos.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.ones([8,320,320,3])\n",
    "b = a.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, h, w, _ = b.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones([8,32,32,2])\n",
    "imgs = tf.ones([8,320,320,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, H, W, _ = imgs.get_shape().as_list()\n",
    "tf.image.resize_images(x, [H,W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_test = {\n",
    "    'ID' : 'test_model',\n",
    "    'n_iter' : 20000,\n",
    "    'n_prt' : 100,\n",
    "    'input_h' : 320,\n",
    "    'input_w' : 320,\n",
    "    'input_ch' : 3,\n",
    "    'n_output' : 10,\n",
    "    'n_batch' : 8,\n",
    "    'n_save' : 1000,\n",
    "    'n_history' : 50,\n",
    "    'LR' : 1e-5,\n",
    "    'random_crop' : False,\n",
    "    'training' : False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SegNet_test = model.Hand3DPoseNet(config=config_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pose 2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_loader = loader.Data('evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, masks, depths, annos = evaluation_loader.load_batch(8)\n",
    "hand_masks = (np.ones(masks.shape) < masks).astype(int)\n",
    "hand_masks = hand_masks[:,:,:,2:]\n",
    "\n",
    "plt.imshow(hand_masks[0,:,:,0], 'gray')\n",
    "plt.show()\n",
    "\n",
    "ud = tf.image.flip_up_down(hand_masks)\n",
    "rl = tf.image.flip_left_right(ud)\n",
    "flipped = sess.run(rl)\n",
    "\n",
    "plt.imshow(flipped[0,:,:,0], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = tf.argmax(hand_masks, axis=1)\n",
    "th = tf.argmax(th, axis=1)\n",
    "tw = tf.argmax(hand_masks, axis=2)\n",
    "tw = tf.argmax(tw, axis=1)\n",
    "\n",
    "flipped = tf.image.flip_left_right(tf.image.flip_up_down(hand_masks))\n",
    "\n",
    "bh = tf.argmax(flipped, axis=1)\n",
    "bh = tf.argmax(bh, axis=1)\n",
    "bw = tf.argmax(flipped, axis=2)\n",
    "bw = tf.argmax(bw, axis=1)\n",
    "\n",
    "th = sess.run(th)[:,0]\n",
    "tw = sess.run(tw)[:,0]\n",
    "bh = sess.run(bh)[:,0]\n",
    "bw = sess.run(bw)[:,0]\n",
    "\n",
    "idx = 0\n",
    "\n",
    "print(th[idx], tw[idx], bh[idx], bw[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hand_masks[0,th[idx]:,:,0], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate center?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, masks, depths, annos = evaluation_loader.load_batch(8)\n",
    "hand_masks = (np.ones(masks.shape) < masks).astype(int)\n",
    "hand_masks = hand_masks[:,:,:,2:]\n",
    "\n",
    "crop_size = 256\n",
    "image = tf.constant(hand_masks, tf.float32)\n",
    "hand_scoremap = tf.constant(hand_masks, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_mask = single_obj_scoremap(hand_scoremap)\n",
    "center, _, crop_size_best = calc_center_bb(hand_mask)\n",
    "crop_size_best *= 1.25\n",
    "scale_crop = tf.minimum(tf.maximum(crop_size / crop_size_best, 0.25), 5.0)\n",
    "\n",
    "image_crop = crop_image_from_xy(image, center, crop_size, scale=scale_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sess.run(image_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "\n",
    "plt.imshow(imgs[idx])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(hand_masks[idx,:,:,0], 'gray')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(t[idx,:,:,0],'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with my model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\n",
    "    'ID' : 'test_sample',\n",
    "    'n_iter' : 10000,\n",
    "    'n_prt' : 100,\n",
    "    'input_h' : 320,\n",
    "    'input_w' : 320,\n",
    "    'input_ch' : 3,\n",
    "    'n_output' : 10,\n",
    "    'n_batch' : 8,\n",
    "    'n_save' : 1000,\n",
    "    'n_history' : 50,\n",
    "    'LR' : 1e-6,\n",
    "    'random_crop' : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SegNet = model.Hand3DPoseNet(config=config2)\n",
    "SegNet.load('./test_handseg/checkpoint/test_handseg_20000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_loader = loader.Data('evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs, masks, depths, annos = evaluation_loader.load_batch(8)\n",
    "mask_pred = SegNet.sess.run(SegNet.hand_seg_pred, feed_dict = {\n",
    "    SegNet.imgs : imgs,\n",
    "    SegNet.masks : masks,\n",
    "    SegNet.depths : depths\n",
    "})\n",
    "\n",
    "mp = np.argmax(mask_pred, axis=3)\n",
    "\n",
    "for idx in range(8):\n",
    "\n",
    "    plt.imshow(imgs[idx])\n",
    "    plt.show()\n",
    "\n",
    "    hands = (np.ones(masks.shape) < masks).astype(int)\n",
    "    plt.imshow(hands[idx,:,:,0], 'gray')\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(mp[idx], 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_masks = (np.ones(masks.shape) < masks).astype(int)\n",
    "hand_masks = hand_masks[:,:,:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = 256\n",
    "image = tf.constant(imgs, tf.float32)\n",
    "hand_scoremap = tf.constant(mask_pred, tf.float32)\n",
    "mp = np.argmax(mask_pred, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_mask = single_obj_scoremap(hand_scoremap)\n",
    "center, _, crop_size_best = calc_center_bb(hand_mask)\n",
    "crop_size_best *= 1.25\n",
    "scale_crop = tf.minimum(tf.maximum(crop_size / crop_size_best, 0.25), 5.0)\n",
    "\n",
    "image_crop = crop_image_from_xy(image, center, crop_size, scale=scale_crop)\n",
    "\n",
    "t = sess.run(image_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 4\n",
    "\n",
    "plt.imshow(imgs[idx])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mp[idx], 'gray')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(t[idx,:,:,0],'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.ones([8,32,32,512])\n",
    "b = tf.ones([8,32,32,21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.dropout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = tf.zeros([8,1])\n",
    "o1 = tf.ones([8,1])\n",
    "tf.concat([z1,o1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.concat([z1,o1],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.layers.flatten(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat([tf.layers.flatten(a), tf.concat([z1,o1],axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat([a,b], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat(tf.concat([a,b], axis=3), tf.constant([1,0], tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annos[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set = 'evaluation'\n",
    "f1 = open('./RHD_published_v2/{}/anno_{}.pickle'.format(set,set), 'rb')\n",
    "anno_all = pickle.load(f1)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_db = './RHD_published_v2/'\n",
    "set = 'evaluation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = 4\n",
    "\n",
    "image = cv2.imread(os.path.join(path_to_db, set , 'color', '%.5d.png' % sample_id))\n",
    "mask = cv2.imread(os.path.join(path_to_db, set , 'mask', '%.5d.png' % sample_id))\n",
    "depth = cv2.imread(os.path.join(path_to_db, set , 'depth', '%.5d.png' % sample_id))\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "depth = cv2.cvtColor(depth, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "hand = (np.ones(mask.shape)*1 < mask).astype(int)\n",
    "hand *= 240\n",
    "plt.imshow(hand)\n",
    "plt.show()\n",
    "anno = anno_all[sample_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno['uv_vis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = anno_all[sample_id]\n",
    "\n",
    "# get info from annotation dictionary\n",
    "kp_coord_uv = anno['uv_vis'][:, :2]  # u, v coordinates of 42 hand keypoints, pixel\n",
    "kp_visible = (anno['uv_vis'][:, 2] == 1)  # visibility of the keypoints, boolean\n",
    "kp_coord_xyz = anno['xyz']  # x, y, z coordinates of the keypoints, in meters\n",
    "camera_intrinsic_matrix = anno['K']  # matrix containing intrinsic parameters\n",
    "\n",
    "# Project world coordinates into the camera frame\n",
    "kp_coord_uv_proj = np.matmul(kp_coord_xyz, np.transpose(camera_intrinsic_matrix))\n",
    "kp_coord_uv_proj = kp_coord_uv_proj[:, :2] / kp_coord_uv_proj[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_coord_uv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_coord_uv[kp_visible].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data\n",
    "fig = plt.figure(1, figsize=(15,15))\n",
    "ax1 = fig.add_subplot('221')\n",
    "ax2 = fig.add_subplot('222')\n",
    "ax3 = fig.add_subplot('223')\n",
    "ax4 = fig.add_subplot('224', projection='3d')\n",
    "\n",
    "ax1.imshow(image)\n",
    "ax1.plot(kp_coord_uv[kp_visible, 0], kp_coord_uv[kp_visible, 1], 'ro')\n",
    "ax1.plot(kp_coord_uv_proj[kp_visible, 0], kp_coord_uv_proj[kp_visible, 1], 'gx')\n",
    "ax2.imshow(depth)\n",
    "ax3.imshow(mask)\n",
    "ax4.scatter(kp_coord_xyz[kp_visible, 0], kp_coord_xyz[kp_visible, 1], kp_coord_xyz[kp_visible, 2])\n",
    "# ax4.view_init(azim=-90.0, elev=-90.0)  # aligns the 3d coord with the camera view\n",
    "# plot_hand_3d(kp_coord_xyz, ax4, color_fixed=None, linewidth='1')\n",
    "# plot_hand(kp_coord_xyz, ax4, color_fixed=None, linewidth='1')\n",
    "ax4.set_xlabel('x')\n",
    "ax4.set_ylabel('y')\n",
    "ax4.set_zlabel('z')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(anno_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask*7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.shape)\n",
    "print(mask.shape)\n",
    "print(depth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()\n",
    "plt.imshow(mask)\n",
    "plt.show()\n",
    "plt.imshow(depth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()\n",
    "plt.imshow(mask)\n",
    "plt.show()\n",
    "plt.imshow(depth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_two_uint8_to_float(top_bits, bottom_bits):\n",
    "    \"\"\" Converts a RGB-coded depth into float valued depth. \"\"\"\n",
    "    depth_map = (top_bits * 2**8 + bottom_bits).astype('float32')\n",
    "    depth_map /= float(2**16 - 1)\n",
    "    depth_map *= 5.0\n",
    "    return depth_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = depth_two_uint8_to_float(depth[:, :, 0], depth[:, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_coord_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = anno_all[sample_id]\n",
    "\n",
    "# get info from annotation dictionary\n",
    "kp_coord_uv = anno['uv_vis'][:, :2]  # u, v coordinates of 42 hand keypoints, pixel\n",
    "kp_visible = (anno['uv_vis'][:, 2] == 1)  # visibility of the keypoints, boolean\n",
    "kp_coord_xyz = anno['xyz']  # x, y, z coordinates of the keypoints, in meters\n",
    "camera_intrinsic_matrix = anno['K']  # matrix containing intrinsic parameters\n",
    "\n",
    "# Project world coordinates into the camera frame\n",
    "kp_coord_uv_proj = np.matmul(kp_coord_xyz, np.transpose(camera_intrinsic_matrix))\n",
    "kp_coord_uv_proj = kp_coord_uv_proj[:, :2] / kp_coord_uv_proj[:, 2:]\n",
    "\n",
    "# Visualize data\n",
    "fig = plt.figure(1, figsize=(15,15))\n",
    "ax1 = fig.add_subplot('221')\n",
    "ax2 = fig.add_subplot('222')\n",
    "ax3 = fig.add_subplot('223')\n",
    "ax4 = fig.add_subplot('224', projection='3d')\n",
    "\n",
    "ax1.imshow(image)\n",
    "ax1.plot(kp_coord_uv[kp_visible, 0], kp_coord_uv[kp_visible, 1], 'ro')\n",
    "ax1.plot(kp_coord_uv_proj[kp_visible, 0], kp_coord_uv_proj[kp_visible, 1], 'gx')\n",
    "ax2.imshow(depth)\n",
    "ax3.imshow(mask)\n",
    "ax4.scatter(kp_coord_xyz[kp_visible, 0], kp_coord_xyz[kp_visible, 1], kp_coord_xyz[kp_visible, 2])\n",
    "# ax4.view_init(azim=-90.0, elev=-90.0)  # aligns the 3d coord with the camera view\n",
    "# plot_hand_3d(kp_coord_xyz, ax4, color_fixed=None, linewidth='1')\n",
    "# plot_hand(kp_coord_xyz, ax4, color_fixed=None, linewidth='1')\n",
    "ax4.set_xlabel('x')\n",
    "ax4.set_ylabel('y')\n",
    "ax4.set_zlabel('z')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_hw = kp_coord_xyz\n",
    "fig = plt.figure(1, figsize=(10,10))\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224, projection='3d')\n",
    "ax1.imshow(image)\n",
    "plot_hand(coord_hw, ax1)\n",
    "ax2.imshow(image_crop_v)\n",
    "plot_hand(coord_hw_crop, ax2)\n",
    "ax3.imshow(np.argmax(hand_scoremap_v, 2))\n",
    "plot_hand_3d(keypoint_coord3d_v, ax4)\n",
    "ax4.view_init(azim=-90.0, elev=-90.0)  # aligns the 3d coord with the camera view\n",
    "ax4.set_xlim([-3, 3])\n",
    "ax4.set_ylim([-3, 1])\n",
    "ax4.set_zlim([-3, 3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hand(coords_hw, axis, color_fixed=None, linewidth='1'):\n",
    "    \"\"\" Plots a hand stick figure into a matplotlib figure. \"\"\"\n",
    "    colors = np.array([[0., 0., 0.5],\n",
    "                       [0., 0., 0.73172906],\n",
    "                       [0., 0., 0.96345811],\n",
    "                       [0., 0.12745098, 1.],\n",
    "                       [0., 0.33137255, 1.],\n",
    "                       [0., 0.55098039, 1.],\n",
    "                       [0., 0.75490196, 1.],\n",
    "                       [0.06008855, 0.9745098, 0.90765338],\n",
    "                       [0.22454143, 1., 0.74320051],\n",
    "                       [0.40164453, 1., 0.56609741],\n",
    "                       [0.56609741, 1., 0.40164453],\n",
    "                       [0.74320051, 1., 0.22454143],\n",
    "                       [0.90765338, 1., 0.06008855],\n",
    "                       [1., 0.82861293, 0.],\n",
    "                       [1., 0.63979666, 0.],\n",
    "                       [1., 0.43645606, 0.],\n",
    "                       [1., 0.2476398, 0.],\n",
    "                       [0.96345811, 0.0442992, 0.],\n",
    "                       [0.73172906, 0., 0.],\n",
    "                       [0.5, 0., 0.]])\n",
    "\n",
    "    # define connections and colors of the bones\n",
    "    bones = [((0, 4), colors[0, :]),\n",
    "             ((4, 3), colors[1, :]),\n",
    "             ((3, 2), colors[2, :]),\n",
    "             ((2, 1), colors[3, :]),\n",
    "\n",
    "             ((0, 8), colors[4, :]),\n",
    "             ((8, 7), colors[5, :]),\n",
    "             ((7, 6), colors[6, :]),\n",
    "             ((6, 5), colors[7, :]),\n",
    "\n",
    "             ((0, 12), colors[8, :]),\n",
    "             ((12, 11), colors[9, :]),\n",
    "             ((11, 10), colors[10, :]),\n",
    "             ((10, 9), colors[11, :]),\n",
    "\n",
    "             ((0, 16), colors[12, :]),\n",
    "             ((16, 15), colors[13, :]),\n",
    "             ((15, 14), colors[14, :]),\n",
    "             ((14, 13), colors[15, :]),\n",
    "\n",
    "             ((0, 20), colors[16, :]),\n",
    "             ((20, 19), colors[17, :]),\n",
    "             ((19, 18), colors[18, :]),\n",
    "             ((18, 17), colors[19, :])]\n",
    "\n",
    "    for connection, color in bones:\n",
    "        coord1 = coords_hw[connection[0], :]\n",
    "        coord2 = coords_hw[connection[1], :]\n",
    "        coords = np.stack([coord1, coord2])\n",
    "        if color_fixed is None:\n",
    "            axis.plot(coords[:, 1], coords[:, 0], color=color, linewidth=linewidth)\n",
    "        else:\n",
    "            axis.plot(coords[:, 1], coords[:, 0], color_fixed, linewidth=linewidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hand_3d(coords_xyz, axis, color_fixed=None, linewidth='1'):\n",
    "    \"\"\" Plots a hand stick figure into a matplotlib figure. \"\"\"\n",
    "    colors = np.array([[0., 0., 0.5],\n",
    "                       [0., 0., 0.73172906],\n",
    "                       [0., 0., 0.96345811],\n",
    "                       [0., 0.12745098, 1.],\n",
    "                       [0., 0.33137255, 1.],\n",
    "                       [0., 0.55098039, 1.],\n",
    "                       [0., 0.75490196, 1.],\n",
    "                       [0.06008855, 0.9745098, 0.90765338],\n",
    "                       [0.22454143, 1., 0.74320051],\n",
    "                       [0.40164453, 1., 0.56609741],\n",
    "                       [0.56609741, 1., 0.40164453],\n",
    "                       [0.74320051, 1., 0.22454143],\n",
    "                       [0.90765338, 1., 0.06008855],\n",
    "                       [1., 0.82861293, 0.],\n",
    "                       [1., 0.63979666, 0.],\n",
    "                       [1., 0.43645606, 0.],\n",
    "                       [1., 0.2476398, 0.],\n",
    "                       [0.96345811, 0.0442992, 0.],\n",
    "                       [0.73172906, 0., 0.],\n",
    "                       [0.5, 0., 0.]])\n",
    "\n",
    "    # define connections and colors of the bones\n",
    "    bones = [((0, 4), colors[0, :]),\n",
    "             ((4, 3), colors[1, :]),\n",
    "             ((3, 2), colors[2, :]),\n",
    "             ((2, 1), colors[3, :]),\n",
    "\n",
    "             ((0, 8), colors[4, :]),\n",
    "             ((8, 7), colors[5, :]),\n",
    "             ((7, 6), colors[6, :]),\n",
    "             ((6, 5), colors[7, :]),\n",
    "\n",
    "             ((0, 12), colors[8, :]),\n",
    "             ((12, 11), colors[9, :]),\n",
    "             ((11, 10), colors[10, :]),\n",
    "             ((10, 9), colors[11, :]),\n",
    "\n",
    "             ((0, 16), colors[12, :]),\n",
    "             ((16, 15), colors[13, :]),\n",
    "             ((15, 14), colors[14, :]),\n",
    "             ((14, 13), colors[15, :]),\n",
    "\n",
    "             ((0, 20), colors[16, :]),\n",
    "             ((20, 19), colors[17, :]),\n",
    "             ((19, 18), colors[18, :]),\n",
    "             ((18, 17), colors[19, :])]\n",
    "\n",
    "    for connection, color in bones:\n",
    "        coord1 = coords_xyz[connection[0], :]\n",
    "        coord2 = coords_xyz[connection[1], :]\n",
    "        coords = np.stack([coord1, coord2])\n",
    "        if color_fixed is None:\n",
    "            axis.plot(coords[:, 0], coords[:, 1], coords[:, 2], color=color, linewidth=linewidth)\n",
    "        else:\n",
    "            axis.plot(coords[:, 0], coords[:, 1], coords[:, 2], color_fixed, linewidth=linewidth)\n",
    "\n",
    "    axis.view_init(azim=-90., elev=90.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20,20))\n",
    "ax1 = fig.add_subplot('221')\n",
    "ax2 = fig.add_subplot('222')\n",
    "ax3 = fig.add_subplot('223')\n",
    "ax4 = fig.add_subplot('224', projection='3d')\n",
    "plot_hand_3d(kp_coord_xyz, ax4, color_fixed=None, linewidth='1')\n",
    "plot_hand(kp_coord_xyz, ax3, color_fixed=None, linewidth='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hand_3d(kp_coord_xyz, ax4, color_fixed=None, linewidth='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# general 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops = NetworkOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_pose2d(image_crop, train=False):\n",
    "    \"\"\" PoseNet: Given an image it detects the 2D hand keypoints.\n",
    "        The image should already contain a rather tightly cropped hand.\n",
    "        Inputs:\n",
    "            image: [B, H, W, 3] tf.float32 tensor, Image with mean subtracted\n",
    "            train: bool, True in case weights should be trainable\n",
    "        Outputs:\n",
    "            scoremap_list_large: list of [B, 256, 256, 21] tf.float32 tensor, Scores for the hand keypoints\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('PoseNet2D'):\n",
    "        scoremap_list = list()\n",
    "        layers_per_block = [2, 2, 4, 2]\n",
    "        out_chan_list = [64, 128, 256, 512]\n",
    "        pool_list = [True, True, True, False]\n",
    "\n",
    "        # learn some feature representation, that describes the image content well\n",
    "        x = image_crop\n",
    "        for block_id, (layer_num, chan_num, pool) in enumerate(zip(layers_per_block, out_chan_list, pool_list), 1):\n",
    "            for layer_id in range(layer_num):\n",
    "                x = ops.conv_relu(x, 'conv%d_%d' % (block_id, layer_id+1), kernel_size=3, stride=1, out_chan=chan_num, trainable=train)\n",
    "            if pool:\n",
    "                x = ops.max_pool(x, 'pool%d' % block_id)\n",
    "\n",
    "        x = ops.conv_relu(x, 'conv4_3', kernel_size=3, stride=1, out_chan=256, trainable=train)\n",
    "        x = ops.conv_relu(x, 'conv4_4', kernel_size=3, stride=1, out_chan=256, trainable=train)\n",
    "        x = ops.conv_relu(x, 'conv4_5', kernel_size=3, stride=1, out_chan=256, trainable=train)\n",
    "        x = ops.conv_relu(x, 'conv4_6', kernel_size=3, stride=1, out_chan=256, trainable=train)\n",
    "        encoding = ops.conv_relu(x, 'conv4_7', kernel_size=3, stride=1, out_chan=128, trainable=train)\n",
    "\n",
    "        # use encoding to detect initial scoremap\n",
    "        x = ops.conv_relu(encoding, 'conv5_1', kernel_size=1, stride=1, out_chan=512, trainable=train)\n",
    "        scoremap = ops.conv(x, 'conv5_2', kernel_size=1, stride=1, out_chan=21, trainable=train)\n",
    "        scoremap_list.append(scoremap)\n",
    "\n",
    "        # iterate recurrent part a couple of times\n",
    "        layers_per_recurrent_unit = 5\n",
    "        num_recurrent_units = 2\n",
    "        for pass_id in range(num_recurrent_units):\n",
    "            x = tf.concat([scoremap_list[-1], encoding], 3)\n",
    "            for rec_id in range(layers_per_recurrent_unit):\n",
    "                x = ops.conv_relu(x, 'conv%d_%d' % (pass_id+6, rec_id+1), kernel_size=7, stride=1, out_chan=128, trainable=train)\n",
    "            x = ops.conv_relu(x, 'conv%d_6' % (pass_id+6), kernel_size=1, stride=1, out_chan=128, trainable=train)\n",
    "            scoremap = ops.conv(x, 'conv%d_7' % (pass_id+6), kernel_size=1, stride=1, out_chan=21, trainable=train)\n",
    "            scoremap_list.append(scoremap)\n",
    "\n",
    "        scoremap_list_large = scoremap_list\n",
    "\n",
    "    return scoremap_list_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_crop = tf.ones([8,320,320,3])\n",
    "k = inference_pose2d(image_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.image.resize_images(k[-1], [256,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gaussian_kernel(kernel_size, sigma, n_channels, dtype):\n",
    "    x = tf.range(-kernel_size // 2 + 1, kernel_size // 2 + 1, dtype=dtype)\n",
    "    g = tf.math.exp(-(tf.pow(x, 2) / (2 * tf.pow(tf.cast(sigma, dtype), 2))))\n",
    "    g_norm2d = tf.pow(tf.reduce_sum(g), 2)\n",
    "    g_kernel = tf.tensordot(g, g, axes=0) / g_norm2d\n",
    "    g_kernel = tf.expand_dims(g_kernel, axis=-1)\n",
    "    return tf.expand_dims(tf.tile(g_kernel, (1, 1, n_channels)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gaussian_kernel(5, 2, 3, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gk = sess.run(_gaussian_kernel(5, 2, 3, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gk[:,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiple_gaussian_map(coords_uv, output_size, sigma, valid_vec=None):\n",
    "    \"\"\" Creates a map of size (output_shape[0], output_shape[1]) at (center[0], center[1])\n",
    "        with variance sigma for multiple coordinates.\"\"\"\n",
    "    with tf.name_scope('create_multiple_gaussian_map'):\n",
    "        sigma = tf.cast(sigma, tf.float32)\n",
    "        assert len(output_size) == 2\n",
    "        s = coords_uv.get_shape().as_list()\n",
    "        coords_uv = tf.cast(coords_uv, tf.int32)\n",
    "        if valid_vec is not None:\n",
    "            valid_vec = tf.cast(valid_vec, tf.float32)\n",
    "            valid_vec = tf.squeeze(valid_vec)\n",
    "            cond_val = tf.greater(valid_vec, 0.5)\n",
    "        else:\n",
    "            cond_val = tf.ones_like(coords_uv[:, 0], dtype=tf.float32)\n",
    "            cond_val = tf.greater(cond_val, 0.5)\n",
    "\n",
    "        cond_1_in = tf.logical_and(tf.less(coords_uv[:, 0], output_size[0]-1), tf.greater(coords_uv[:, 0], 0))\n",
    "        cond_2_in = tf.logical_and(tf.less(coords_uv[:, 1], output_size[1]-1), tf.greater(coords_uv[:, 1], 0))\n",
    "        cond_in = tf.logical_and(cond_1_in, cond_2_in)\n",
    "        cond = tf.logical_and(cond_val, cond_in)\n",
    "\n",
    "        coords_uv = tf.cast(coords_uv, tf.float32)\n",
    "\n",
    "        # create meshgrid\n",
    "        x_range = tf.expand_dims(tf.range(output_size[0]), 1)\n",
    "        y_range = tf.expand_dims(tf.range(output_size[1]), 0)\n",
    "\n",
    "        X = tf.cast(tf.tile(x_range, [1, output_size[1]]), tf.float32)\n",
    "        Y = tf.cast(tf.tile(y_range, [output_size[0], 1]), tf.float32)\n",
    "\n",
    "        X.set_shape((output_size[0], output_size[1]))\n",
    "        Y.set_shape((output_size[0], output_size[1]))\n",
    "\n",
    "        X = tf.expand_dims(X, -1)\n",
    "        Y = tf.expand_dims(Y, -1)\n",
    "\n",
    "        X_b = tf.tile(X, [1, 1, s[0]])\n",
    "        Y_b = tf.tile(Y, [1, 1, s[0]])\n",
    "\n",
    "        X_b -= coords_uv[:, 0]\n",
    "        Y_b -= coords_uv[:, 1]\n",
    "\n",
    "        dist = tf.square(X_b) + tf.square(Y_b)\n",
    "\n",
    "        scoremap = tf.exp(-dist / tf.square(sigma)) * tf.cast(cond, tf.float32)\n",
    "\n",
    "        return scoremap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_uv = [[0,0],[10,10],[15,15],[20,20]]\n",
    "coords_uv = tf.constant(coords_uv, tf.float32)\n",
    "coords_uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_uv = tf.stack([anno['uv_vis'][:,0], anno['uv_vis'][:,1]], -1)\n",
    "coords_uv = tf.cast(coords_uv, tf.int32)\n",
    "coords_uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_vec = anno['uv_vis'][:,2]\n",
    "valid_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_multiple_gaussian_map(coords_uv, [256,256], 25, [1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sess.run(create_multiple_gaussian_map(coords_uv, [256,256], 25, valid_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(a[:,:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.gather?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno['uv_vis'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(kp_visible, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.array(kp_coord_uv[kp_visible, 0]).astype(int)\n",
    "v = np.array(kp_coord_uv[kp_visible, 1]).astype(int)\n",
    "\n",
    "tfkp = tf.stack([u,v],-1)\n",
    "tfkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tfkp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_coord_uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfkp[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.sparse_to_dense(tfkp[2:3], [256,256], sparse_values=1.0)\n",
    "b = sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.expand_dims(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.nn.depthwise_conv2d(tf.expand_dims(a,2), _gaussian_kernel, [1,1,1,1], 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(b==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info from annotation dictionary\n",
    "kp_coord_uv = anno['uv_vis'][:, :2]  # u, v coordinates of 42 hand keypoints, pixel\n",
    "kp_visible = (anno['uv_vis'][:, 2] == 1)  # visibility of the keypoints, boolean\n",
    "kp_coord_xyz = anno['xyz']  # x, y, z coordinates of the keypoints, in meters\n",
    "camera_intrinsic_matrix = anno['K']  # matrix containing intrinsic parameters\n",
    "\n",
    "# Project world coordinates into the camera frame\n",
    "kp_coord_uv_proj = np.matmul(kp_coord_xyz, np.transpose(camera_intrinsic_matrix))\n",
    "kp_coord_uv_proj = kp_coord_uv_proj[:, :2] / kp_coord_uv_proj[:, 2:]\n",
    "\n",
    "# Visualize data\n",
    "fig = plt.figure(1, figsize=(15,15))\n",
    "ax1 = fig.add_subplot('221')\n",
    "ax2 = fig.add_subplot('222')\n",
    "ax3 = fig.add_subplot('223')\n",
    "ax4 = fig.add_subplot('224', projection='3d')\n",
    "\n",
    "ax1.imshow(image)\n",
    "ax1.plot(kp_coord_uv[kp_visible, 0], kp_coord_uv[kp_visible, 1], 'ro')\n",
    "ax1.plot(kp_coord_uv_proj[kp_visible, 0], kp_coord_uv_proj[kp_visible, 1], 'gx')\n",
    "ax2.imshow(depth)\n",
    "ax3.imshow(mask)\n",
    "ax4.scatter(kp_coord_xyz[kp_visible, 0], kp_coord_xyz[kp_visible, 1], kp_coord_xyz[kp_visible, 2])\n",
    "# ax4.view_init(azim=-90.0, elev=-90.0)  # aligns the 3d coord with the camera view\n",
    "# plot_hand_3d(kp_coord_xyz, ax4, color_fixed=None, linewidth='1')\n",
    "# plot_hand(kp_coord_xyz, ax4, color_fixed=None, linewidth='1')\n",
    "ax4.set_xlabel('x')\n",
    "ax4.set_ylabel('y')\n",
    "ax4.set_zlabel('z')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
